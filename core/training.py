# ===========================================
# Archivo: core/training.py (v2.0) - CON AUDITORÃA DE FEATURES
# Ahora incluye anÃ¡lisis de importancia y detecciÃ³n de features inÃºtiles
# ===========================================
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_absolute_error
import joblib
import json
import os
import numpy as np

# ğŸ†• IMPORTS ACTUALIZADOS PARA LA NUEVA ESTRUCTURA
from config import DATA_FOLDER, MODELS_FOLDER, PROCESSED_FILES_PATH, FEATURES_TO_USE
from core.features import calculate_features
from core.data_processing import load_league_data

def load_processed_files():
    """Carga la lista de archivos ya procesados."""
    if os.path.exists(PROCESSED_FILES_PATH):
        try:
            with open(PROCESSED_FILES_PATH, 'r', encoding='utf-8') as f:
                return json.load(f)
        except (json.JSONDecodeError, FileNotFoundError):
            return []
    return []

def save_processed_files(files_list):
    """Guarda la lista actualizada de archivos procesados."""
    with open(PROCESSED_FILES_PATH, 'w', encoding='utf-8') as f:
        json.dump(files_list, f)

def analyze_feature_importance(model, feature_names, league_name):
    """
    ğŸ” NUEVA FUNCIÃ“N: Analiza quÃ© features realmente usa el modelo
    """
    print(f"\n{'='*60}")
    print(f"ğŸ” AUDITORÃA DE FEATURES - Liga: {league_name}")
    print(f"{'='*60}")
    
    importances = model.feature_importances_
    feature_importance = list(zip(feature_names, importances))
    
    # Ordenar por importancia
    feature_importance.sort(key=lambda x: x[1], reverse=True)
    
    # ğŸ¯ TOP FEATURES MÃS IMPORTANTES
    print(f"\nğŸ¯ TOP 15 FEATURES MÃS IMPORTANTES:")
    total_importance_top15 = 0
    for i, (feature, importance) in enumerate(feature_importance[:15]):
        total_importance_top15 += importance
        print(f"{i+1:2d}. {feature:<40} {importance:.4f} ({importance*100:.1f}%)")
    
    print(f"\nğŸ“Š Las top 15 features representan {total_importance_top15*100:.1f}% del poder predictivo")
    
    # âŒ BOTTOM FEATURES MENOS ÃšTILES  
    print(f"\nâŒ BOTTOM 15 FEATURES MENOS ÃšTILES:")
    bottom_15 = feature_importance[-15:]
    total_importance_bottom15 = 0
    for i, (feature, importance) in enumerate(bottom_15):
        total_importance_bottom15 += importance
        rank = len(feature_importance) - 14 + i
        print(f"{rank:2d}. {feature:<40} {importance:.4f} ({importance*100:.1f}%)")
    
    print(f"\nğŸ“‰ Las bottom 15 features solo aportan {total_importance_bottom15*100:.1f}% del poder predictivo")
    
    # ğŸ—‘ï¸ FEATURES POSIBLEMENTE INÃšTILES
    useless_threshold = 0.001  # Menos de 0.1% de importancia
    useless_features = [f for f, imp in feature_importance if imp < useless_threshold]
    
    if useless_features:
        print(f"\nğŸ—‘ï¸ FEATURES POSIBLEMENTE INÃšTILES ({len(useless_features)} features con <0.1% importancia):")
        for i, feature in enumerate(useless_features, 1):
            importance = next(imp for f, imp in feature_importance if f == feature)
            print(f"{i:2d}. {feature:<40} {importance:.6f}")
        
        print(f"\nğŸ’¡ RECOMENDACIÃ“N: Considera eliminar estas {len(useless_features)} features para:")
        print(f"   âœ… Reducir tiempo de entrenamiento")
        print(f"   âœ… Acelerar predicciones")
        print(f"   âœ… Reducir overfitting")
        print(f"   âœ… Simplificar el modelo")
    else:
        print(f"\nâœ… Todas las features tienen importancia significativa (>0.1%)")
    
    # ğŸ“Š ESTADÃSTICAS GENERALES
    print(f"\nğŸ“Š ESTADÃSTICAS GENERALES:")
    print(f"   Total features: {len(feature_names)}")
    print(f"   Features Ãºtiles (>0.1%): {len(feature_names) - len(useless_features)}")
    print(f"   Features posiblemente inÃºtiles: {len(useless_features)}")
    print(f"   ConcentraciÃ³n top 10: {sum(imp for _, imp in feature_importance[:10])*100:.1f}%")
    print(f"   ConcentraciÃ³n top 25: {sum(imp for _, imp in feature_importance[:25])*100:.1f}%")
    
    return {
        'feature_importance': feature_importance,
        'useless_features': useless_features,
        'top_15_importance': total_importance_top15,
        'bottom_15_importance': total_importance_bottom15,
        'stats': {
            'total_features': len(feature_names),
            'useful_features': len(feature_names) - len(useless_features),
            'useless_features': len(useless_features),
            'top_10_concentration': sum(imp for _, imp in feature_importance[:10]),
            'top_25_concentration': sum(imp for _, imp in feature_importance[:25])
        }
    }

def test_model_without_features(X, y, features_to_remove, league_name):
    """
    ğŸ§ª NUEVA FUNCIÃ“N: Prueba precisiÃ³n sin ciertas features
    """
    if not features_to_remove:
        print(f"\nâœ… No hay features para eliminar en {league_name}")
        return None
    
    print(f"\n{'='*50}")
    print(f"ğŸ§ª PRUEBA DE ELIMINACIÃ“N - {league_name}")
    print(f"{'='*50}")
    
    # Modelo original
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
    model_original = RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1)
    model_original.fit(X_train, y_train)
    y_pred_original = model_original.predict(X_test)
    mae_original = mean_absolute_error(y_test, y_pred_original)
    
    # Modelo sin features sospechosas
    features_available = [f for f in features_to_remove if f in X.columns]
    if not features_available:
        print(f"âš ï¸ Ninguna de las features a eliminar estÃ¡ presente en el dataset")
        return None
        
    X_reduced = X.drop(columns=features_available, errors='ignore')
    
    X_train_red, X_test_red, y_train_red, y_test_red = train_test_split(X_reduced, y, test_size=0.2, random_state=42)
    model_reduced = RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1)
    model_reduced.fit(X_train_red, y_train_red)
    y_pred_reduced = model_reduced.predict(X_test_red)
    mae_reduced = mean_absolute_error(y_test_red, y_pred_reduced)
    
    # Comparar resultados
    mae_difference = mae_reduced - mae_original
    percentage_change = (mae_difference / mae_original) * 100
    
    print(f"ğŸ“Š RESULTADOS DE LA PRUEBA:")
    print(f"   Features eliminadas: {len(features_available)}")
    print(f"   Features restantes: {len(X_reduced.columns)}")
    print(f"   MAE original: {mae_original:.3f}")
    print(f"   MAE sin features: {mae_reduced:.3f}")
    print(f"   Diferencia: {mae_difference:+.3f} ({percentage_change:+.1f}%)")
    
    if mae_difference <= 0:
        print(f"   ğŸ‰ RESULTADO: Modelo MEJORA o se mantiene igual sin estas features!")
        print(f"   ğŸ’¡ RECOMENDACIÃ“N: ELIMINAR estas features del modelo")
    elif percentage_change < 2:
        print(f"   âœ… RESULTADO: PÃ©rdida mÃ­nima (<2%) - Considerar eliminar por simplicidad")
    elif percentage_change < 5:
        print(f"   ğŸ¤” RESULTADO: PÃ©rdida moderada (2-5%) - Evaluar trade-off velocidad vs precisiÃ³n")
    else:
        print(f"   âŒ RESULTADO: PÃ©rdida significativa (>5%) - MANTENER estas features")
    
    return {
        'features_removed': features_available,
        'features_remaining': len(X_reduced.columns),
        'mae_original': mae_original,
        'mae_reduced': mae_reduced,
        'mae_difference': mae_difference,
        'percentage_change': percentage_change,
        'recommendation': 'ELIMINAR' if mae_difference <= 0 else 'MANTENER' if percentage_change > 5 else 'EVALUAR'
    }

def train_models_by_league():
    """Carga los datos, entrena un modelo por liga y los guarda CON AUDITORÃA."""
    print("ğŸ”„ MODO DE ENTRENAMIENTO CON AUDITORÃA ACTIVADO...")
    
    if not os.path.exists(MODELS_FOLDER):
        os.makedirs(MODELS_FOLDER)

    processed_files = load_processed_files()
    
    # Usar el nuevo sistema de carga de datos
    all_data = load_league_data(DATA_FOLDER)
    
    # Actualizar archivos procesados
    for filename in os.listdir(DATA_FOLDER):
        if filename.endswith(".json") and filename not in processed_files:
            processed_files.append(filename)
                
    save_processed_files(processed_files)

    # ğŸ“Š RESULTADOS DE AUDITORÃA GLOBAL
    global_audit_results = {}

    for league, league_data in all_data.items():
        print(f"\n{'ğŸ€'*20}")
        print(f"ğŸ€ PROCESANDO Y ENTRENANDO: '{league}'")
        print(f"{'ğŸ€'*20}")
        
        total_matches_found = len(league_data)
        print(f"ğŸ“Š Total de partidos encontrados: {total_matches_found}")

        df = calculate_features(league_data)
        
        num_valid_data_points = len(df)
        print(f"ğŸ“Š Data points vÃ¡lidos para entrenamiento: {num_valid_data_points}")
        
        if df.empty or num_valid_data_points < 20:
            print(f"âŒ No hay suficientes datos vÃ¡lidos. Se necesitan al menos 20 partidos. Saltando.")
            continue

        features_for_this_model = [f for f in FEATURES_TO_USE if f in df.columns]
        X = df[features_for_this_model]
        y = df['final_total_score']
        
        print(f"ğŸ¯ Features incluidas en el modelo: {len(features_for_this_model)}")
        
        # ğŸ”„ ENTRENAMIENTO NORMAL
        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
        
        model = RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1)
        model.fit(X_train, y_train)

        y_pred = model.predict(X_test)
        mae = mean_absolute_error(y_test, y_pred)
        residuals = y_test - y_pred
        std_dev = np.std(residuals)
        
        print(f"âœ… Entrenamiento completado:")
        print(f"   MAE: {mae:.2f}")
        print(f"   Std Dev: {std_dev:.2f}")
        
        # ğŸ” AUDITORÃA DE FEATURES
        audit_results = analyze_feature_importance(model, features_for_this_model, league)
        
        # ğŸ§ª PRUEBA DE ELIMINACIÃ“N (solo si hay features inÃºtiles)
        if audit_results['useless_features']:
            elimination_results = test_model_without_features(
                X, y, audit_results['useless_features'], league
            )
            audit_results['elimination_test'] = elimination_results
        else:
            audit_results['elimination_test'] = None
        
        # Guardar resultados de auditorÃ­a
        global_audit_results[league] = audit_results
        
        # ğŸ’¾ GUARDAR MODELO (incluyendo auditorÃ­a)
        team_names = list(set(df['home_team'].unique().tolist() + df['away_team'].unique().tolist()))
        
        # Crear valores de imputaciÃ³n
        impute_values = {}
        if not df[features_for_this_model].empty:
            impute_values = df[features_for_this_model].mean().to_dict()
        else:
            impute_values = {f: 0.0 for f in features_for_this_model}

        trained_data = {
            'model': model,
            'features_used': features_for_this_model,
            'std_dev': std_dev,
            'historical_df': df,
            'team_names': team_names,
            'league_name': league,
            'impute_values': impute_values,
            'audit_results': audit_results  # ğŸ†• INCLUIR AUDITORÃA
        }
        
        safe_league_name = league.replace(" ", "_").replace("(", "").replace(")", "").replace("/", "_")
        model_filename = os.path.join(MODELS_FOLDER, f"{safe_league_name}.joblib")
        joblib.dump(trained_data, model_filename)
        
        print(f"ğŸ’¾ Modelo guardado: {model_filename}")
        print(f"ğŸ“Š Equipos: {len(team_names)} | Partidos: {len(df)} | Features: {len(features_for_this_model)}")
    
    # ğŸ“‹ RESUMEN GLOBAL DE AUDITORÃA
    print(f"\n{'='*80}")
    print(f"ğŸ“‹ RESUMEN GLOBAL DE AUDITORÃA")
    print(f"{'='*80}")
    
    total_leagues = len(global_audit_results)
    total_useless_features = sum(len(results['useless_features']) for results in global_audit_results.values())
    avg_feature_count = np.mean([results['stats']['total_features'] for results in global_audit_results.values()])
    avg_concentration = np.mean([results['stats']['top_10_concentration'] for results in global_audit_results.values()])
    
    print(f"ğŸ† Ligas procesadas: {total_leagues}")
    print(f"ğŸ“Š Promedio de features por liga: {avg_feature_count:.1f}")
    print(f"ğŸ¯ ConcentraciÃ³n promedio top 10: {avg_concentration*100:.1f}%")
    print(f"ğŸ—‘ï¸ Total features potencialmente inÃºtiles: {total_useless_features}")
    
    if total_useless_features > 0:
        print(f"\nğŸ’¡ RECOMENDACIÃ“N GLOBAL:")
        print(f"   Considera crear una versiÃ³n optimizada eliminando features inÃºtiles")
        print(f"   Beneficios esperados: +25-30% velocidad, menos overfitting")
    else:
        print(f"\nâœ… EXCELENTE: Todas las features parecen contribuir al modelo")
    
    print(f"\nğŸ‰ AUDITORÃA COMPLETA! Revisa los resultados arriba para optimizar tu modelo.")

if __name__ == "__main__":
    train_models_by_league()