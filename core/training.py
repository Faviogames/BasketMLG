# ===========================================
# Archivo: core/training.py (v3.1) - SISTEMA DUAL COMPLETO
# Entrena RF y XGBoost simult√°neamente con selecci√≥n de modelo
# ===========================================
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_absolute_error
import joblib
import json
import os
import numpy as np

# Imports del proyecto
from config import DATA_FOLDER, MODELS_FOLDER, PROCESSED_FILES_PATH, FEATURES_TO_USE
from core.features import calculate_features
from core.data_processing import load_league_data

# Import del sistema dual
try:
    from core.dual_models import DualModelSystem
    DUAL_SYSTEM_AVAILABLE = True
    print("‚úÖ Sistema dual cargado correctamente")
except ImportError as e:
    DUAL_SYSTEM_AVAILABLE = False
    print(f"‚ö†Ô∏è Sistema dual no disponible: {e}")
    print("üîÑ Continuando con Random Forest solamente...")

def load_processed_files():
    """Carga la lista de archivos ya procesados."""
    if os.path.exists(PROCESSED_FILES_PATH):
        try:
            with open(PROCESSED_FILES_PATH, 'r', encoding='utf-8') as f:
                return json.load(f)
        except (json.JSONDecodeError, FileNotFoundError):
            return []
    return []

def save_processed_files(files_list):
    """Guarda la lista actualizada de archivos procesados."""
    with open(PROCESSED_FILES_PATH, 'w', encoding='utf-8') as f:
        json.dump(files_list, f)

def analyze_feature_importance(model, feature_names, league_name):
    """
    üîç Analiza qu√© features realmente usa el modelo
    """
    if not hasattr(model, 'feature_importances_'):
        print(f"‚ö†Ô∏è El modelo {type(model).__name__} no tiene 'feature_importances_'. Saltando auditor√≠a.")
        return {
            'feature_importance': [],
            'useless_features': [],
            'stats': {
                'total_features': len(feature_names),
                'top_10_concentration': 0.0,
            }
        }

    print(f"\n{'='*60}")
    print(f"üîç AUDITOR√çA DE FEATURES - {league_name}")
    print(f"{'='*60}")
    
    importances = model.feature_importances_
    feature_importance = list(zip(feature_names, importances))
    feature_importance.sort(key=lambda x: x[1], reverse=True)
    
    # TOP 15 features m√°s importantes
    print(f"\nüéØ TOP 15 FEATURES M√ÅS IMPORTANTES:")
    total_importance_top15 = 0
    for i, (feature, importance) in enumerate(feature_importance[:15]):
        total_importance_top15 += importance
        print(f"{i+1:2d}. {feature:<40} {importance:.4f} ({importance*100:.1f}%)")
    
    print(f"\nüìä Las top 15 features representan {total_importance_top15*100:.1f}% del poder predictivo")
    
    # Features in√∫tiles
    useless_threshold = 0.001
    useless_features = [f for f, imp in feature_importance if imp < useless_threshold]
    
    if useless_features:
        print(f"\nüóëÔ∏è FEATURES POTENCIALMENTE IN√öTILES ({len(useless_features)} features con <0.1% importancia):")
        for i, feature in enumerate(useless_features[:10]):  # Solo primeros 10
            importance = next(imp for f, imp in feature_importance if f == feature)
            print(f"{i+1:2d}. {feature:<40} {importance:.6f}")
        
        if len(useless_features) > 10:
            print(f"... y {len(useless_features) - 10} m√°s")
    else:
        print(f"\n‚úÖ Todas las features tienen importancia significativa (>0.1%)")
    
    return {
        'feature_importance': feature_importance,
        'useless_features': useless_features,
        'stats': {
            'total_features': len(feature_names),
            'useful_features': len(feature_names) - len(useless_features),
            'useless_features': len(useless_features),
            'top_10_concentration': sum(imp for _, imp in feature_importance[:10]),
            'top_25_concentration': sum(imp for _, imp in feature_importance[:25])
        }
    }

def train_single_model_legacy(X_train, y_train, X_test, y_test):
    """
    Entrenamiento legacy con Random Forest (fallback)
    """
    print("üå≤ Entrenando Random Forest (modo legacy)...")
    
    model = RandomForestRegressor(n_estimators=100, random_state=42, n_jobs=-1)
    model.fit(X_train, y_train)
    
    y_pred = model.predict(X_test)
    mae = mean_absolute_error(y_test, y_pred)
    residuals = y_test - y_pred
    std_dev = np.std(residuals)
    
    print(f"‚úÖ Random Forest: MAE = {mae:.3f}, Std Dev = {std_dev:.3f}")
    
    return {
        'model': model,
        'mae': mae,
        'std_dev': std_dev,
        'model_type': 'random_forest'
    }

def train_models_by_league():
    """Carga los datos, entrena modelos por liga y los guarda."""
    print("üîÑ INICIANDO ENTRENAMIENTO...")
    
    if DUAL_SYSTEM_AVAILABLE:
        print("ü§ñ MODO: Sistema Dual (RF + XGBoost)")
    else:
        print("üå≤ MODO: Random Forest solamente")
    
    if not os.path.exists(MODELS_FOLDER):
        os.makedirs(MODELS_FOLDER)

    processed_files = load_processed_files()
    all_data = load_league_data(DATA_FOLDER)
    
    if not all_data:
        print("‚ùå No se encontraron datos para procesar")
        return
    
    # Actualizar archivos procesados
    for filename in os.listdir(DATA_FOLDER):
        if filename.endswith(".json") and filename not in processed_files:
            processed_files.append(filename)
    save_processed_files(processed_files)

    # üìä Resultados de auditor√≠a global
    global_audit_results = {}

    for league, league_data in all_data.items():
        print(f"\n{'üèÄ'*20}")
        print(f"üèÄ PROCESANDO Y ENTRENANDO: '{league}'")
        print(f"{'üèÄ'*20}")
        
        total_matches_found = len(league_data)
        print(f"üìä Total de partidos encontrados: {total_matches_found}")

        # Calcular features
        try:
            df = calculate_features(league_data)
        except Exception as e:
            print(f"‚ùå Error calculando features para {league}: {e}")
            continue
        
        num_valid_data_points = len(df)
        print(f"üìä Data points v√°lidos para entrenamiento: {num_valid_data_points}")
        
        if df.empty or num_valid_data_points < 20:
            print(f"‚ùå No hay suficientes datos v√°lidos para '{league}'. Se necesitan al menos 20. Saltando.")
            continue

        # Preparar datos
        features_for_this_model = [f for f in FEATURES_TO_USE if f in df.columns]
        X = df[features_for_this_model]
        y = df['final_total_score']
        
        print(f"üéØ Features incluidas en el modelo: {len(features_for_this_model)}")
        
        # Divisi√≥n train/test
        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
        
        # --- ENTRENAMIENTO ---
        if DUAL_SYSTEM_AVAILABLE:
            print(f"\nüöÄ INICIANDO SISTEMA DUAL...")
            
            try:
                # Crear sistema dual
                dual_system = DualModelSystem()
                
                # Verificar modelos disponibles
                available_models = dual_system.get_available_models()
                print(f"üìä Modelos disponibles: {available_models}")
                
                if len(available_models) < 2:
                    print(f"‚ö†Ô∏è Solo {len(available_models)} modelo(s) disponible(s). Usando entrenamiento simple.")
                    model_result = train_single_model_legacy(X_train, y_train, X_test, y_test)
                    selected_model_type = 'random_forest'
                else:
                    # Pasar datos adicionales al sistema
                    dual_system.features_used = features_for_this_model
                    dual_system.historical_df = df
                    dual_system.team_names = list(set(df['home_team'].unique().tolist() + df['away_team'].unique().tolist()))
                    dual_system.impute_values = df[features_for_this_model].mean().to_dict()
                    
                    # Entrenar todos los modelos
                    print(f"üöÄ Entrenando {len(available_models)} modelos...")
                    all_results = dual_system.train_all_models(X_train, y_train, X_test, y_test)
                    
                    # --- SELECCI√ìN DE MODELO ---
                    # üéØ CONFIGURA AQU√ç TU PREFERENCIA
                    model_preference = "interactive"  # Opciones: "auto", "random_forest", "xgboost", "interactive"
                    
                    print(f"\nüéØ M√©todo de selecci√≥n: {model_preference}")
                    
                    # Obtener modelo seg√∫n preferencia
                    selected_model_type, model_result = dual_system.get_model_by_preference(model_preference)
                    
                    if not model_result:
                        print(f"‚ùå No se pudo seleccionar un modelo para {league}. Usando Random Forest.")
                        model_result = train_single_model_legacy(X_train, y_train, X_test, y_test)
                        selected_model_type = 'random_forest'
                    else:
                        print(f"\nüéØ MODELO SELECCIONADO PARA {league}: {selected_model_type.upper()}")
                
            except Exception as e:
                print(f"‚ùå Error en sistema dual: {e}")
                print("üîÑ Fallback a entrenamiento legacy...")
                model_result = train_single_model_legacy(X_train, y_train, X_test, y_test)
                selected_model_type = 'random_forest'
        else:
            # Entrenamiento legacy
            model_result = train_single_model_legacy(X_train, y_train, X_test, y_test)
            selected_model_type = 'random_forest'
        
        # Extraer datos del resultado
        model = model_result['model']
        mae = model_result['mae']
        std_dev = model_result['std_dev']
        
        print(f"‚úÖ Entrenamiento completado:")
        print(f"   Modelo: {selected_model_type.upper()}")
        print(f"   MAE: {mae:.2f}")
        print(f"   Std Dev: {std_dev:.2f}")
        
        # üîç AUDITOR√çA DE FEATURES
        audit_results = analyze_feature_importance(model, features_for_this_model, f"{league} ({selected_model_type})")
        global_audit_results[f"{league}_{selected_model_type}"] = audit_results
        
        # --- GUARDADO DE MODELOS ---
        team_names = list(set(df['home_team'].unique().tolist() + df['away_team'].unique().tolist()))
        
        # Crear valores de imputaci√≥n
        impute_values = {}
        if not df[features_for_this_model].empty:
            impute_values = df[features_for_this_model].mean().to_dict()
        else:
            impute_values = {f: 0.0 for f in features_for_this_model}

        # Datos del modelo principal (compatibilidad con c√≥digo existente)
        trained_data = {
            'model': model,
            'model_type': selected_model_type,
            'features_used': features_for_this_model,
            'std_dev': std_dev,
            'historical_df': df,
            'team_names': team_names,
            'league_name': league,
            'impute_values': impute_values,
            'audit_results': audit_results,
            'mae': mae
        }
        
        # Guardar modelo principal
        safe_league_name = league.replace(" ", "_").replace("(", "").replace(")", "").replace("/", "_")
        model_filename = os.path.join(MODELS_FOLDER, f"{safe_league_name}.joblib")
        joblib.dump(trained_data, model_filename)
        
        print(f"üíæ Modelo principal guardado: {safe_league_name}.joblib")
        
        # Guardar modelos duales si est√°n disponibles
        if DUAL_SYSTEM_AVAILABLE and 'dual_system' in locals() and hasattr(dual_system, 'results') and dual_system.results:
            try:
                saved_files, primary_model = dual_system.save_models(league, MODELS_FOLDER, selected_model_type)
                print(f"üíæ Modelos duales guardados: {len(saved_files)} archivos")
            except Exception as e:
                print(f"‚ö†Ô∏è Error guardando modelos duales: {e}")
        
        print(f"üìä Resumen: {len(team_names)} equipos | {len(df)} partidos | {len(features_for_this_model)} features")

    # üìã RESUMEN GLOBAL DE AUDITOR√çA
    print(f"\n{'='*80}")
    print(f"üìã RESUMEN GLOBAL DE AUDITOR√çA")
    print(f"{'='*80}")
    
    total_leagues = len(global_audit_results)
    print(f"üèÜ Ligas procesadas: {total_leagues}")
    
    if global_audit_results:
        # Estad√≠sticas promedio
        avg_feature_count = np.mean([results['stats']['total_features'] for results in global_audit_results.values() if results.get('stats')])
        avg_concentration = np.mean([results['stats']['top_10_concentration'] for results in global_audit_results.values() if results.get('stats')])
        total_useless_features = sum(len(results['useless_features']) for results in global_audit_results.values())
        
        print(f"üìä Promedio de features por liga: {avg_feature_count:.1f}")
        print(f"üéØ Concentraci√≥n promedio top 10: {avg_concentration*100:.1f}%")
        print(f"üóëÔ∏è Total features potencialmente in√∫tiles: {total_useless_features}")
        
        if total_useless_features > 0:
            print(f"\nüí° RECOMENDACI√ìN GLOBAL:")
            print(f"   Considera crear una versi√≥n optimizada eliminando features in√∫tiles")
            print(f"   Beneficios esperados: +25-30% velocidad, menos overfitting")
        else:
            print(f"\n‚úÖ EXCELENTE: Todas las features parecen contribuir al modelo")
    
    print(f"\nüéâ ENTRENAMIENTO COMPLETADO!")
    
    if DUAL_SYSTEM_AVAILABLE:
        print(f"ü§ñ Sistema dual utilizado con √©xito")
    else:
        print(f"üå≤ Sistema legacy Random Forest utilizado")

if __name__ == "__main__":
    train_models_by_league()